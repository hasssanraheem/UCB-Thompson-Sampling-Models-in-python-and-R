# UCB-Thompson-Sampling-Models-in-python-and-R
This repository contains implementations of two widely used multi-armed bandit algorithms: Upper Confidence Bound (UCB) and Thompson Sampling.
Each algorithm is organized in its own folder with:

Python and R scripts for implementation

Simulation scripts for testing

Explanations of the algorithm and its parameters

Algorithms Included

Upper Confidence Bound (UCB) – Balances exploration and exploitation using confidence intervals for action selection.

Thompson Sampling – Probabilistic algorithm that selects actions based on Bayesian posterior sampling.

Repository Structure

Reinforcement-Learning-Algorithms/

UCB/

Thompson_Sampling/

Each folder contains:

Python and R implementation scripts

Simulation scripts for multi-armed bandit experiments

A README explaining the algorithm, parameters, and evaluation approach

Features

Implementations in Python and R

Clean, well-commented code for learning purposes

Simulations to test algorithm performance

Easy to modify parameters for exploration vs exploitation

Learning Benefits

Understand fundamental multi-armed bandit algorithms

Learn to implement reinforcement learning strategies in Python and R

Experiment with different parameters to observe algorithm behavior
